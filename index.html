<!doctype html>
<html lang="en">

<!--
Copyright (C) 2016 Mikhail Pak
CC-BY-NC-SA 4.0

This slide deck uses reveal.js by Hakim El Hattab.
Copyright (C) 2016 Hakim El Hattab, http://hakim.se
MIT License
-->

<head>
	<meta charset="utf-8">

	<link href="https://fonts.googleapis.com/css?family=Open+Sans:200|Raleway:200" rel="stylesheet">

	<title>Two derivations of the Kalman filter</title>

	<meta name="description" content="Two derivations of the Kalman filter">
	<meta name="author" content="Mikhail Pak">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/my_theme.css" id="theme">

	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
</head>


<body>
<div class="reveal">
<div class="slides">

<section class="center">
	<h2>Two derivations of the Kalman filter</h2>
	<small>
		<p><a href="https://github.com/mp4096">Mikhail Pak</a>, July 2016</p>
		<p>CC-BY-NC-SA 4.0</p>
	</small>
</section>

<section>
	<h3>Outline</h3>
	<ul>
		<li><p>Introduction</p></li>
		<li><p>Inference in linear dynamical systems</p></li>
		<li><p>Frequentist derivation: MVUE</p></li>
		<li><p>Bayesian derivation: Iterative belief update</p></li>
		<li><p>Comparison of frequentist and Bayesian approaches</p></li>
		<li><p>Nonlinear and non-Gaussian extensions</p></li>
	</ul>
</section>

<section>
	<h3>Introduction</h3>

	<p>
		We shall see a derivation of the Kalman filter from a frequentist and a
		Bayesianist statistician’s point of view.
	</p>
	<p>
		I argue that the Bayesian way of incorporating the prior explicitly is
		more intuitive and suits control theory better.
	</p>
</section>

<section>
	<section>
		<h3>Inference in linear dynamical systems</h3>
		<p>Consider an autonomous linear dynamical system</p>
		<script type="math/tex; mode=display">
			\begin{align}
				\label{eq:lds:dynamics}
				x_k &= A_k x_{k - 1} + w_k, \\
				\label{eq:lds:measurement}
				y_k &= C_k x_k + v_k
			\end{align}
		</script>
		<p>
			where $x_k \in \mathbb{R}^n$, $y_k \in \mathbb{R}^q$;
			$A_k \in \mathbb{R}^{n \times n}$, $C_k \in \mathbb{R}^{q \times n}$.
			Random variables $w_k \in \mathbb{R}^n$, $v_k \in \mathbb{R}^q$ are
			temporally white and spatially Gaussian with $\mathbb{E}
			\{ w_k \} = 0$, $\mathbb{E} \{ v_k \} = 0$ and $\mathrm{cov}\,{w_k} = Q_k$,
			$\mathrm{cov}\,{v_k} = R_k$.
			The initial state is given by a Gaussian pdf $\mathcal{N}(x_0, P_0)$.
		</p>
		<p class="fragment">
			Furthermore, assume that $C_k$ is rank deficient and that
			covariance matrices $Q_k$, $R_k$ are positive definite at any time $k$.
		</p><br />
		<p class="fragment">
			We can now formulate the <em>filtering problem:</em><br>
			Given the sequence $y_0$, $y_1$, ..., $y_k$,
			what is the best estimate $\hat{x}_k$ for the current state $x_k$?
		</p>
	</section>
</section>

<section>
	<h3>Inference in linear dynamical systems</h3>
	<p>We will now present two different approaches to solve this problem:</p>
	<ul>
		<li><p>Frequentist derivation of a minimum variance unbiased estimator (MVUE);</p></li>
		<li><p>Bayesian derivation of an iterative belief update.</p></li>
	</ul>
	<p class="fragment">Both of them will lead to the Kalman filter.</p>
	<p class="fragment">
		Of course one can derive the Kalman filter in a number of other ways,
		e.g. based on orthogonal projections (Kalman’s own approach, cf. [2]),
		maximum likelihood (ML) or maximum a posteriori (MAP).
	</p>
</section>

<section>
	<h3>Frequentist derivation: MVUE</h3>
	<p>We want to derive a minimum variance unbiased estimator (MVUE):</p>
	<ul>
		<li class="fragment">
			<p><em>minimum variance:</em> the error variance should be minimised:</p>
			<script type="math/tex; mode=display">
				\mathrm{cov}\,(\hat{x}_k - x_k) =: P_k,
			</script><br>
			<script type="math/tex; mode=display">
				\min \mathrm{tr}\,{P_k} \ \ \forall k, \quad \mathrm{tr}\,{P_k} = \sum_i \sigma_i^2 .
			</script>
		</p></li>
		<li class="fragment">
			<p><em>unbiased:</em> the expectation of the estimation error should be zero:</p>
			<script type="math/tex; mode=display">
				\mathbb{E}\{\hat{x}_k - x_k\} = 0.
			</script>
		</li>
	</ul>
</section>

<section>
	<h3>Frequentist derivation 1/5</h3>
	<p>
		Since $w_k$, $v_k$ are temporally white and spatially Gaussian,
		the MVUE is a linear filter with the following
		linear dynamical system structure [3]:
	</p>
	<script type="math/tex; mode=display">
		\label{eq:mvue:lds:assumption}
		\hat{x}_k = \mathcal{A}_k \hat{x}_{k - 1} + \mathcal{K}_k y_k.
	</script>
	<p>
		We define the estimation error $\tilde{x}_k = \hat{x}_k - x_k$
		and plug the filter and plant dynamics into it.
	</p>
	<p>After some linear algebra, we obtain $\tilde{x}_k$:</p>
	<script type="math/tex; mode=display">
		\tilde{x}_k
		=
		\mathcal{A}_k \tilde{x}_{k - 1}
		+
		\left( (\mathcal{K}_k C_k - I) A_{k - 1} + \mathcal{A}_k \right) x_{k - 1}
		+
		\left( \mathcal{K}_k C_k - I \right) w_k
		+
		\mathcal{K}_k v_k.
	</script>
	<p>
		However, we are interested in the <em>expected value</em>
		of the estimation error:
	</p>
	<script type="math/tex; mode=display">
		\begin{align}
			\mathbb{E}\{\tilde{x}_k\}
			=
			&\mathcal{A}_k \mathbb{E}\{\tilde{x}_{k - 1}\}
			+
			\left( (\mathcal{K}_k C_k - I) A_{k - 1} + \mathcal{A}_k \right) \mathbb{E}\{x_{k - 1}\}
			+ \\
			&\left( \mathcal{K}_k C_k - I \right) \mathbb{E}\{w_k\}
			+
			\mathcal{K}_k \mathbb{E}\{v_k\}.
		\end{align}
	</script>
	<p>
		Clearly, $(\mathcal{K}_k C_k - I) A_{k - 1} + \mathcal{A}_k \stackrel{!}{=} 0$
		to satisfy the unbiasedness requirement. Hence,
	</p>
	<script type="math/tex; mode=display">
		\mathcal{A}_k = (I - \mathcal{K}_k C_k) A_{k - 1}.
	</script><br />
</section>
<section>
	<h3>Frequentist derivation 2/5</h3>
	<p>
		Now, let’s take a look at the minimum variance requirement.</p><p>
		Define $A_{k - 1} \hat{x}_{k - 1}$ as the <em>estimate prediction</em>
		$\hat{x}_k^-$ and $C_k \hat{x}_k^-$ as the <em>measurement estimate prediction</em>
		$\hat{y}_k^-$.
	</p>
	<p>Then, we can write the filter dynamics as</p>
	<script type="math/tex; mode=display">
		\hat{x}_k = \hat{x}_k^- + \mathcal{K}_k (y_k - \hat{y}_k^-)
	</script>
	<p>and the estimate prediction error as</p>
	<script type="math/tex; mode=display">
		\tilde{x}_k^- = A_{k - 1} \tilde{x}_{k - 1} - w_k.
	</script>
</section>
<section>
	<h3>Frequentist derivation 3/5</h3>
	<p>
		We now derive the estimate prediction error covariance
		$P_k^- := \mathrm{cov}\, \tilde{x}_k^-$.
		We shall need it later for the estimate error covariance
		$P_k := \mathrm{cov}\, \tilde{x}_k$.
	</p>
	<p>
		Observe that the $\mathbb{E}\{\tilde{x}_k^-\} = 0$.
		Hence, $P_k^- = \mathrm{cov}\, \tilde{x}_k^- = \mathbb{E}\{ (\tilde{x}_k^-) (\tilde{x}_k^-)^\mathrm{T} \}$.
		Taking into account that the estimate as well as its prediction are uncorrelated with
		$w_k$, we obtain
	</p>
	<script type="math/tex; mode=display">
		P_k^- = A_{k - 1} P_{k - 1} A_{k - 1}^\mathrm{T} + Q_k.
	</script>
</section>
<section>
	<h3>Frequentist derivation 4/5</h3>
	<p>After even more tedious manipulations, we can show that</p>
	<script type="math/tex; mode=display">
		\tilde{x}_k = (I - \mathcal{K}_k C_k) \tilde{x}_k^- + \mathcal{K}_k v_k
	</script>
	<p>and thus</p>
	<script type="math/tex; mode=display">
		P_k = (I - \mathcal{K}_k C_k) P_k^- (I - \mathcal{K}_k C_k)^\mathrm{T} +
		\mathcal{K}_k R_k \mathcal{K}_k^\mathrm{T}.
	</script><br>
	<p>Let’s expand this expression and take its trace:</p>
	<script type="math/tex; mode=display">
		\mathrm{tr}\, P_k
		=
		\mathrm{tr}\, P_k^-
		-
		2 \mathrm{tr}\, \mathcal{K}_k C_k P_k^-
		+
		\mathrm{tr}\, \mathcal{K}_k C_k P_k^- C_k^\mathrm{T} \mathcal{K}_k^\mathrm{T}
		+
		\mathrm{tr}\, \mathcal{K}_k R_k \mathcal{K}_k^\mathrm{T}.
	</script>
</section>
<section>
	<h3>Frequentist derivation 5/5</h3>
	<p>
		We now look for the minimiser
		$\mathcal{K}_k^* = \arg \min \mathrm{tr}\, P_k$:
	</p>
	<script type="math/tex; mode=display">
		\frac{\partial}{\partial \mathcal{K}_k} \mathrm{tr}\, P_k
		=
		- 2 P_k^- C_k^\mathrm{T}
		+ 2 \mathcal{K}_k C_k P_k^- C_k^\mathrm{T}
		+ 2 \mathcal{K}_k R_k
		\stackrel{!}{=} 0.
	</script><br>
	<p>This minimiser is the <em>Kalman gain</em>:</p>
	<script type="math/tex; mode=display">
		\label{eq:kalman:gain:mvue}
		K_k = \mathcal{K}_k^* =
		P_k^- C_k^\mathrm{T}
		\left( C_k P_k^- C_k^\mathrm{T} + R_k \right)^{-1}.
	</script>
</section>

<section>
	<h3>Bayesian derivation: Iterative belief update</h3>
	<p>Let’s revise Bayesian inference before we start solving the filtering problem.</p>
	<p>All derivations will be based on Bayes’ theorem:</p>
	<script type="math/tex; mode=display">
		p(A \ | \ B) = \frac{p(B \ | \ A) \ p(A)}{p(B)}
	</script>
	or, informally:
	<script type="math/tex; mode=display">
		p(\text{State} \ | \ \text{Measurements} )
		=
		\frac{
			p(\text{Measurements} \ | \ \text{State} )\ p(\text{State})
		}{
			p(\text{Measurements})
		}.
	</script></p>

	<p>Here,<ul>
		<li><p>$p(\text{State}\ |\ \text{Measurements})$ is the <em>posterior</em>;</p></li>
		<li><p>$p(\text{Measurements}\ |\ \text{State})$ is the <em>likelihood</em>;</p></li>
		<li><p>$p(\text{State})$ is the <em>prior</em>;</p></li>
		<li><p>$p(\text{Measurements})$ is the <em>total likelihood</em>.</p></li>
	</ul></p>
</section>

<section>
	<h3>Intermission: Multivariate normal pdf</h3>
	<p>In the following,</p>
	<script type="math/tex; mode=display">
		\left. \mathcal{N}(\mu, \ \Sigma) \right|_x
	</script>
	<p>
		will denote the multivariate normal pdf with mean
		$\mu \in \mathbb{R}^n$ and covariance
		$\Sigma \in \mathbb{R}^{n \times n}$
		evaluated at $x$:
	</p>
	<script type="math/tex; mode=display">
		\left. \mathcal{N}(\mu, \ \Sigma) \right|_x
		=
		\frac{1}{\sqrt{(2 \pi)^n \det{\Sigma}}}
		\mathrm{exp}\!\left( -\frac{1}{2} (x - \mu)^\mathrm{T} \Sigma^{-1} (x - \mu) \right).
	</script>
</section>

<section>
	<h3>Bayesian derivation 1/6</h3>
	<p>
		Denote a sequence of measurements $y_0$, $y_1$, … $y_k$
		by $\mathcal{Y}_k$.
	</p>
	<p>We can now apply Bayes’ theorem for our filtering problem:</p>
	<script type="math/tex; mode=display">
		\label{eq:bayes:kf}
		p(x_k \ | \ y_k, \mathcal{Y}_{k - 1})
		=
		\frac{%
		  p(y_k \ | \ x_k, \mathcal{Y}_{k - 1})
		  \ %
		  p(x_k \ | \ \mathcal{Y}_{k - 1})
		}{%
		  p(y_k \ | \ \mathcal{Y}_{k - 1})
		}.
	</script><br>
	<p>Let’s take a closer look at all of these terms.</p>
</section>

<section>
	<h3>Bayesian derivation 2/6</h3>
	<p>
		<em>Posterior:</em>
		Gives the probability distribution for the estimate
		$x_k$ after measuring $y_k$ and $\mathcal{Y}_{k - 1}$.
		Since all pdfs involved are Gaussian, we can assume
		the posterior to be given by
	</p>
	<script type="math/tex; mode=display">
		p(x_k \ | \ y_k, \mathcal{Y}_{k - 1})
		=
		\left. \mathcal{N}(\hat{x}_k, \ P_k) \right|_{x_k}.
	</script><br>
	<p>
		This is the pdf we’re looking for! We ‘only’ have to find the
		closed-form solution for the posterior estimate mean $\hat{x}_k$
		and estimate error covariance $P_k$.
	</p><br>
	<p>
		<em>Likelihood:</em>
		Gives the probability of measuring $y_k$
		given $x_k$ and all previous measurements $\mathcal{Y}_{k - 1}$.
		Notice that this is a function of $x_k$ with fixed $y_k$!
	</p>
	<script type="math/tex; mode=display">
		p(y_k \ | \ x_k, \mathcal{Y}_{k - 1})
		=
		\left. \mathcal{N}(C_k x_k, \ R_k) \right|_{y_k}.
	</script>
</section>

<section>
	<h3>Bayesian derivation 3/6</h3>
	<p>
		<em>Prior:</em>
		Gives the probability distribution for the estimate $x_k$
		based on the previous measurements $\mathcal{Y}_{k - 1}$
		(which are ‘packed’ into the previous estimate $\hat{x}_{k - 1}$):
	</p>
	<script type="math/tex; mode=display">
		\begin{aligned}
		  p(x_k \ | \ \mathcal{Y}_{k - 1})
		  &=
		  \label{eq:transition:chapman:kolmogorov}
		  \int p(x_k \ | \ x_{k - 1}) \ p(x_{k - 1} \ | \ \mathcal{Y}_{k - 1}) dx_{k - 1} \\
		  &=
		  \int \left. \mathcal{N}(A_{k - 1} x_{k - 1}, \ Q_k) \right|_{x_k} \  \left. \mathcal{N}(\hat{x}_{k - 1}, \ P_{k - 1}) \right|_{x_{k - 1}} dx_{k - 1}  \\
		  &=
		  \label{eq:marginalised:prior}
		  \left. \mathcal{N}(A_{k - 1} \hat{x}_{k - 1}, \ A_{k - 1} P_{k - 1} A_{k - 1}^\mathrm{T} + Q_k) \right|_{x_k} \\
		  &=
		  \left. \mathcal{N}(\hat{x}_k^-, \ P_k^-) \right|_{x_k}.
		\end{aligned}
	</script><br>
	<p>We used [4, (2.115), p. 93] to obtain this result.</p>
</section>

<section>
	<h3>Bayesian derivation 4/6</h3>
	<p>
		<em>Total likelihood:</em>
		Gives the non-conditional probability distribution for the measurement
		$y_k$, i.e. over all possible states $x_k$. We obtain it by marginalising
		over $x_k$:
	</p>
	<script type="math/tex; mode=display">
		\begin{aligned}
		  p(y_k \ | \ \mathcal{Y}_{k - 1})
		  &=
		  \int p(y_k, x_k \ | \ \mathcal{Y}_{k - 1}) dx_k \\
		  &=
		  \label{eq:measurement:chapman:kolmogorov}
		  \int p(y_k \ | \ x_k) \  p(x_k \ | \ \mathcal{Y}_{k - 1}) dx_k \\
		  &=
		  \int \left. \mathcal{N}(C_k x_k, \ R_k) \right|_{y_k} \ \left. \mathcal{N}(\hat{x}_k^-, \ P_k^-) \right|_{x_k} dx_k \\
		  &=
		  \label{eq:marginalised:total}
		  \left. \mathcal{N}(C_k \hat{x}_k^-, \ C_k P_k^- C_k^\mathrm{T} + R_k) \right|_{y_k} \\
		  &=
		  \left. \mathcal{N}(\hat{y}_k^-, \ C_k P_k^- C_k^\mathrm{T} + R_k) \right|_{y_k}
		\end{aligned}
	</script><br>
	<p>We used [4, (2.115), p. 93] to obtain this result.</p>
</section>

<section>
	<h3>Bayesian derivation 5/6</h3>
	<p>So far, we have</p>
	<script type="math/tex; mode=display">
		p(x_k \ | \ y_k, \mathcal{Y}_{k - 1})
		=
		\frac{%
		  \left. \mathcal{N}(C_k x_k, \ R_k) \right|_{y_k} %
		  \ %
		  \left. \mathcal{N}(\hat{x}_k^-, \ P_k^-) \right|_{x_k} %
		}{%
		  \left. \mathcal{N}(\hat{y}_k^-, \ C_k P_k^- C_k^\mathrm{T} + R_k) \right|_{y_k}
		}.
	</script><br>
	<p>Recall the Gaussian pdf. One can show [5, Theorem 2, p. 60], [6] that</p>
	<script type="math/tex; mode=display">
		\left. \mathcal{N}(C_k x_k, \ R_k) \right|_{y_k} %
		\ %
		\left. \mathcal{N}(\hat{x}_k^-, \ P_k^-) \right|_{x_k} %
		=
		\left. \mathcal{N}(\hat{x}_k, \ P_k) \right|_{x_k} %
		\ %
		\left. \mathcal{N}(y_k, \ C_k P_k^- C_k^\mathrm{T} + R_k ) \right|_{\hat{y}_k^-}
	</script>
	<p>
		with
		<script type="math/tex; mode=display">
			\begin{aligned}
				\label{eq:posterior:mean}
				\hat{x}_k &= \hat{x}_k^- + P_k C_k^\mathrm{T} R_k^{-1} (y_k - \hat{y}_k^-), \\
				P_k  &= \left( (P_k^-)^{-1} + C_k^\mathrm{T} R_k^{-1} C_k \right)^{-1}.
				% = \left( I - P_k^- C_k^\mathrm{T} (C_k P_k^- C_k^\mathrm{T} + R_k)^{-1} C_k \right) P_k^-.
			\end{aligned}
		</script><br>
	</p>
	<p>
		Obviously,
		$\left. \mathcal{N}(\mu, \ \Sigma ) \right|_x = \left. \mathcal{N}(x, \ \Sigma ) \right|_{\mu}$.
		Hence,
	</p>
	<script type="math/tex; mode=display">
		p(x_k \ | \ y_k, \mathcal{Y}_{k - 1})
		=
		\left. \mathcal{N}(\hat{x}_k, \ P_k) \right|_{x_k}.
	</script>
</section>

<section>
	<h3>Bayesian derivation 6/6</h3>
	<p>
		But wait! The gain in the posterior mean does not look as the Kalman gain
		we derived for the MVUE… or does it?
	</p>
	<script type="math/tex; mode=display">
		\begin{aligned}
			C_k^\mathrm{T}
			&=
			C_k^\mathrm{T}, \\
			%
			%
			C_k^\mathrm{T} R_k^{-1} C_k P_k^- C_k^\mathrm{T} + C_k^\mathrm{T}
			&=
			C_k^\mathrm{T} R_k^{-1} C_k P_k^- C_k^\mathrm{T} + C_k^\mathrm{T}, \\
			%
			%
			C_k^\mathrm{T} R_k^{-1} \left( C_k P_k^- C_k^\mathrm{T} + R_k \right)
			&=
			\left( (P_k^-)^{-1} + C_k^\mathrm{T} R_k^{-1} C_k \right) P_k^- C_k^\mathrm{T}, \\
			%
			%
			\left( (P_k^-)^{-1} + C_k^\mathrm{T} R_k^{-1} C_k \right)^{-1} C_k^\mathrm{T} R_k^{-1}
			&=
			P_k^- C_k^\mathrm{T} \left( C_k P_k^- C_k^\mathrm{T} + R_k \right)^{-1}, \\
			%
			%
			P_k C_k^\mathrm{T} R_k^{-1} &= K_k.
		\end{aligned}
	</script><br />
	<p>
		Remember that covariance matrices are positive definite and
		$X P X^\mathrm{T}$ is at least positive semi-definite if
		$P$ is positive definite [7, p. 431].
		Thus, $(P_k^-)^{-1} + C_k^\mathrm{T} R_k^{-1} C_k$ and
		$C_k P_k^- C_k^\mathrm{T} + R_k$ are always invertible.
	</p>
</section>

<section>
	<h3>Comparison of frequentist and Bayesian approaches</h3>
	<p>Frequentist approach:</p>
	<ul>
		<li><p>No explicit prior; it comes implicitly from the fact that the MVUE is a linear dynamical system;</p></li>
		<li><p>This result itself, although conceptually simple, is quite hard to obtain, cf. [3] for the proof.</p></li>
	</ul>
	<p>Bayesian approach:</p>
	<ul>
		<li><p>The prior is taken explicitly into account;</p></li>
		<li><p>Absolutely no optimality was required: we just applied Bayes’ theorem;</p></li>
		<li><p>
			Unfortunately, this straightforward approach is possible only in the Gaussian setting;
			computation of conditional probabilities becomes quickly intractable for other distributions.
		</p></li>
	</ul>
</section>
<section>
	<h3>Nonlinear and non-Gaussian extensions</h3>
	<p>
		<em>What happens if the process or measurement noise is not normally distributed?</em><br />
		In this case, the Kalman filter is still the optimal <em>linear</em> estimator for arbitrary
		quadratic loss functions, cf. [2, Theorem 2, p. 38].
		However, it is neither unbiased nor minimum variance anymore.
	</p>
	<p>
		<em>What if the system dynamics or the measurement equation is nonlinear?</em><br />
		In this case, one can either linearise the dynamics and measurement equations around the
		current estimate or perform a stochastic linearisation.
		The former approach is known as the <em>extended Kalman filter</em> (EKF) and the latter as
		the <em>unscented Kalman filter</em> (UKF).
	</p>
	<p>
		The principal advantage of EKF and UKF is their computational tractability.
		On the downside, both of them can perform arbitrarily badly.
		See [8, Fig. 1, p. 6] for an example of degeneracy of the unscented transformation.
	</p>
	<p>
		If fast computation of estimates is not required, one can use a <em>particle filter</em>
		to approximate the conditional probabilities with a sequential Monte Carlo approach.
		The estimation error in a particle filter converges to zero as the number of particles
		approaches infinity [9, p. 480].
	</p>
</section>


<section>
	<h3>References</h3><small>
	<p>
		[1] Sam Roweis and Zoubin Ghahramani.
		A unifying review of linear Gaussian models.
		Neural Computation, 11(2): 305–345, Feb 1999.
		DOI: <a href="http://dx.doi.org/10.1162/089976699300016674">10.1162/089976699300016674</a>.
	</p>
	<p>
		[2] Rudolph Emil Kálmán.
		A new approach to linear filtering and prediction problems.
		Transactions of the ASME–Journal of Basic Engineering, 82(Series D): 35–45, 1960.
	</p>
	<p>
		[3] Vladimir S. Pugachev.
		A possible general solution of the problem of determination of an optimal dynamical system.
		Automation and Remote Control, 17(7): 585–589, 1956.
	</p>
	<p>
		[4] Christopher M. Bishop.
		Pattern Recognition and Machine Learning.
		Springer-Verlag New York Inc., 2006.
		ISBN 0387310738.
	</p>
	<p>
		[5] A.L. Barker, D.E. Brown, and W.N. Martin.
		Bayesian estimation and the Kalman filter.
		Computers &amp; Mathematics with Applications, 30(10): 55–77, Nov 1995.
		DOI: <a href="http://dx.doi.org/10.1016/0898-1221(95)00156-S">10.1016/0898-1221(95)00156-s</a>.
	</p>
	<p>
		[6] D.J. Salmond.
		Tracking in uncertain environments.
		Technical Memorandum AW121, Royal Aerospace Establishment,
		1989.
	</p>
	<p>
		[7] Roger A. Horn and Charles R. Johnson.
		Matrix Analysis.
		Cambridge University Press, 2nd edition, 2013.
		ISBN 978-0-521-54823-6.
	</p>
	<p>
		[8] Marc Peter Deisenroth, Ryan Darby Turner, Marco F. Huber,
		Uwe D. Hanebeck, and Carl Edward Rasmussen.
		Robust filtering and smoothing with Gaussian processes.
		IEEE Transactions on Automatic Control, 57(7): 1865–1871, Jul 2012.
		DOI: <a href="http://dx.doi.org/10.1109/TAC.2011.2179426">10.1109/tac.2011.2179426</a>.
	<p>
		[9] Dan Simon. Optimal State Estimation.
		John Wiley &amp; Sons Inc, 2006.
		ISBN 0471708585.
	</p>
	</small>
</section>
</div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
	Reveal.initialize({
		controls: true,
		progress: true,
		history: true,
		center: false,

		transition: 'fade', // none/fade/slide/convex/concave/zoom

		math: {
			// mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
			config: 'TeX-AMS_HTML-full'
		},

		dependencies: [
			{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
			{ src: 'plugin/math/math.js', async: true }
		]
	});
</script>
</body>
</html>
